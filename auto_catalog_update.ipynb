{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# import warnings\n",
    "\n",
    "# def fxn():\n",
    "#     warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "#     fxn()\n",
    "\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.utils import formataddr\n",
    "\n",
    "import pandas as pd\n",
    "import time, requests, csv, json\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 20000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import sys, os, shutil, pdb\n",
    "sys.path.insert(1, '/Users/muhammadfaisal/Documents/')\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, clear_output\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "try: # running remotely\n",
    "    from google.colab import drive \n",
    "except: # running locally\n",
    "    from utils import *\n",
    "    from engine import GDrive\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local VS Remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_scripts():\n",
    "    # downloading utils and engine scripts from github\n",
    "    r=requests.get(\"https://raw.githubusercontent.com/faysal887/tricyons-analyser-v2/master/engine.py\")\n",
    "    with open('engine.py', 'w') as f: f.write(r.content.decode(\"utf-8\"))\n",
    "\n",
    "    r=requests.get(\"https://raw.githubusercontent.com/faysal887/tricyons-analyser-v2/master/utils.py\")\n",
    "    with open('utils.py', 'w') as f: f.write(r.content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'drive' is not defined\n",
      "running locally\n",
      "GDrive already connected!\n"
     ]
    }
   ],
   "source": [
    "LOCAL=None # running code locally or remotely\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    GoogleAuth.DEFAULT_SETTINGS['client_config_file'] = '/content/drive/MyDrive/Colab Notebooks/client_secrets.json'\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.GetAuthUrl()\n",
    "    print('running on collab')\n",
    "    LOCAL=False\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('running locally')\n",
    "    LOCAL=True\n",
    "\n",
    "\n",
    "if LOCAL: # running locally\n",
    "    try:\n",
    "        if g: print('GDrive already connected!')\n",
    "    except: \n",
    "        g=GDrive()\n",
    "        print('created new connection!')\n",
    "else: # running remotely\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    GoogleAuth.DEFAULT_SETTINGS['client_config_file'] = '/content/drive/MyDrive/Colab Notebooks/client_secrets.json'\n",
    "    gauth = GoogleAuth()\n",
    "    print(gauth.GetAuthUrl())\n",
    "    redirect_url=input('Enter redirect url')\n",
    "    code=redirect_url.split('code=')[1].split('&scope=')[0]\n",
    "    gauth.Authenticate(code)\n",
    "    download_scripts()\n",
    "    from utils import *\n",
    "    from engine import GDrive\n",
    "    g=GDrive(gauth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DIR='./tmp'\n",
    "try: shutil.rmtree(TMP_DIR)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1\n",
      "(32, 12)\n",
      "done 2\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "tmp_dir='./tmp'\n",
    "merged_dir=f'{tmp_dir}/merged'\n",
    "online_catalogs=f'{tmp_dir}/online_catalogs'\n",
    "gdrive_catalogs=f'{tmp_dir}/gdrive_catalogs'\n",
    "\n",
    "# 1. create /tmp if not\n",
    "Path(tmp_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(merged_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(online_catalogs).mkdir(parents=True, exist_ok=True)\n",
    "Path(gdrive_catalogs).mkdir(parents=True, exist_ok=True)\n",
    "print('done 1')\n",
    "\n",
    "# 2. download excel sheet for links and emails \n",
    "tree=['Supplier Catalogues', 'AUTOMATION', 'Brands For Auto-Email']\n",
    "folder_id=g.find_gdrive_folder_id(tree=tree, folder_id='root')\n",
    "g.download_files(folder_id, tmp_dir)\n",
    "\n",
    "linksdf=pd.read_excel(f'{tmp_dir}/Catalogs Link.xlsx')\n",
    "# data=linksdf.dropna(subset=['Link'], axis=0)\n",
    "data=strip_column_names(linksdf)\n",
    "print(data.shape)\n",
    "print('done 2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 12)\n",
      "29/19\n",
      " ************************************************* \n",
      "\n",
      "Error Catalogs:  {}\n",
      "\n",
      " ************************************************* \n",
      "\n",
      "done 3\n"
     ]
    }
   ],
   "source": [
    "# 3. download excel catalogs\n",
    "df=data[(data.Active==True) & (data.Type=='LINK')]\n",
    "print(df.shape)\n",
    "catalogs=download_online_excel_catalogs(df, online_catalogs, test_catalogs=[])\n",
    "print('done 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. delete existing supplier folders\n",
    "tree_base=['Supplier Catalogues', 'AUTOMATION', 'Catalogs_ALL']\n",
    "df.Distributor.apply(lambda x: g.delete_by_name(tree_base+[x]))\n",
    "print('done 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. create new supplier folders\n",
    "tree=['Supplier Catalogues', 'AUTOMATION', 'Catalogs_ALL']\n",
    "parent_folder_id=g.find_gdrive_folder_id(tree=tree, folder_id='root')\n",
    "df['folder_id'] = df.Distributor.apply(lambda x: g.create_folder(parent_folder_id, x))\n",
    "print('done 5')\n",
    "\n",
    "\n",
    "# 6. create folder for catalog in supplier folder\n",
    "df['catalog_folder_id'] = df.folder_id.apply(lambda x: g.create_folder(parent_folder_id=x, folder_name='catalog'))\n",
    "print('done 6')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. upload catalog\n",
    "# _ = df.apply(lambda x: g.upload_file(folder_id=x.catalog_folder_id, file_path=f'{online_catalogs}/{x.Distributor}.xlsx'), axis=1)\n",
    "for i, row in df.iterrows():\n",
    "    print(f'{i+1}/{len(df)}', end='\\r')\n",
    "    file_path=f'{online_catalogs}/{row.Distributor}.xlsx'\n",
    "    if os.path.exists(file_path):\n",
    "        g.upload_file(folder_id=row.catalog_folder_id, file_path=file_path)\n",
    "    \n",
    "print('done 7')\n",
    "\n",
    "\n",
    "# 8. delete /tmp\n",
    "# shutil.rmtree(tmp_dir)\n",
    "# print('done 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "                                # PART-2: Start again with data #\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "df=data[data.Active==True].copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 8. for all the suppliers in catalogs_all, get their catalog folder_ids \n",
    "for i, row in df.iterrows():\n",
    "    try:\n",
    "        print(f'{i+1}/{len(df)}', end='\\r')\n",
    "        tree=['Supplier Catalogues', 'AUTOMATION', 'Catalogs_ALL', row.Distributor, 'catalog']\n",
    "        catalog_folder_id=g.find_gdrive_folder_id(tree=tree, folder_id='root')\n",
    "        df.loc[i, 'catalog_folder_id']=catalog_folder_id\n",
    "    except Exception as e:\n",
    "        print('Error: ', row['Distributor'], e)\n",
    "print('done 8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. loop on supplier folders id df and download all catalogs from gdrive\n",
    "# _ = df.catalog_folder_id.apply(lambda x: g.download_files(gdrive_folder_id=x, local_folder_path=gdrive_catalogs))\n",
    "\n",
    "for i, row in df[['Distributor','catalog_folder_id']].iterrows():\n",
    "    print(f'{i+1}/{len(df)}', end='\\r')\n",
    "\n",
    "    try:\n",
    "        dist, _id=row['Distributor'], row['catalog_folder_id']\n",
    "        g.download_files(gdrive_folder_id=_id, local_folder_path=gdrive_catalogs)\n",
    "    except Exception as e:\n",
    "        print('Error: ', dist, e)\n",
    "print('done 9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. create new catalogs dict obj\n",
    "\n",
    "catalogs={}\n",
    "for i, fn in enumerate(os.listdir(gdrive_catalogs)):\n",
    "    print(f'{i+1}/{len(os.listdir(gdrive_catalogs))}', end='\\r')\n",
    "\n",
    "    if '.xlsx' in fn or 'xls' in fn: tmpdf=pd.read_excel(f'{gdrive_catalogs}/{fn}')\n",
    "    if '.csv'   in fn: tmpdf=pd.read_csv(f'{gdrive_catalogs}/{fn}')\n",
    "\n",
    "    fn=fn.split('.')[0]\n",
    "\n",
    "    catalogs[fn]=tmpdf\n",
    "    # catalogs[fn.replace('.xlsx','').replace('.csv','').replace('.csv','')]=tmpdf\n",
    "\n",
    "print('done 10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks to check all the required columns are present\n",
    "for name, tmpdf in catalogs.items():\n",
    "    # pdb.set_trace()\n",
    "    id_columns_name\t= df[df.Distributor==name].id_columns_name.item()\n",
    "    id_columns_type = df[df.Distributor==name].id_columns_type.item()\n",
    "    price_column    = df[df.Distributor==name].price_column.item()\n",
    "\n",
    "    if id_columns_name not in tmpdf.columns: print(f'{name} {id_columns_name} column missing')\n",
    "    if price_column not in tmpdf.columns: print(f'{name} {price_column} column missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. label data\n",
    "df, catalogs=label_data(df, catalogs)\n",
    "print('done 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess each supplier separately\n",
    "for name, tmpdf in catalogs.items():\n",
    "    if name == 'NUK': tmpdf=preprocess_nuk(tmpdf)\n",
    "    catalogs[name]=tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode supplier name in df dataframe\n",
    "# keys=df.Distributor.unique().tolist()\n",
    "# values=['TRI'+str(i).zfill(5) for i in range(len(keys))]\n",
    "# labels_map=dict(zip(keys, values))\n",
    "# df['distributor_key'] = df.Distributor.map(labels_map)\n",
    "\n",
    "# now this is being done manually\n",
    "# print('done 12')\n",
    "\n",
    "\n",
    "# apply labels_map for each catalog in catalog dict of dfs\n",
    "for key, tmpdf in catalogs.items():\n",
    "    tmpdf['distributor_key']=df[df.Distributor==key].distributor_key.item()\n",
    "    catalogs[key]=tmpdf\n",
    "\n",
    "\n",
    "# 12. upload updated catalog_links df\n",
    "# df.drop(['folder_id', 'catalog_folder_id'], axis=1).to_excel(f'{tmp_dir}/Catalogs Link.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. check for missing values in each column\n",
    "missing_total=0\n",
    "for name, tmpdf in catalogs.items():\n",
    "    # print(name, tmpdf['each_price'].isnull().sum())\n",
    "    missing_total+=tmpdf['each_price'].isnull().sum()\n",
    "print(missing_total)\n",
    "print('done 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. preprocess asins\n",
    "asins_suppliers=df[df.id_columns_type=='asin'].Distributor.tolist()\n",
    "\n",
    "asinsdf = pd.concat([catalogs[x][['asin', 'each_price', 'distributor_key']] for x in asins_suppliers])\n",
    "print('after concating all asinsdf: ',asinsdf.shape, asinsdf.each_price.isnull().sum())\n",
    "\n",
    "asinsdf=asinsdf.dropna()\n",
    "print('after dropna: ',asinsdf.shape, asinsdf.each_price.isnull().sum())\n",
    "\n",
    "asinsdf=preprocess_price(asinsdf)\n",
    "print('after preprocess_price: ',asinsdf.shape, asinsdf.each_price.isnull().sum())\n",
    "\n",
    "asinsdf=asinsdf.reset_index(drop=True)\n",
    "print('after reset_index: ',asinsdf.shape, asinsdf.each_price.isnull().sum())\n",
    "\n",
    "asinsdf.to_excel(f'{merged_dir}/asinsdf.xlsx', index=False)\n",
    "print('after saving: ', asinsdf.shape)\n",
    "print('done 13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. preprocess upcs\n",
    "upc_suppliers=df[df.id_columns_type=='upc'].Distributor.tolist()\n",
    "upcsdf = pd.concat([catalogs[x][['upc', 'each_price', 'distributor_key']] for x in upc_suppliers])\n",
    "print('after concat: ',upcsdf.shape, upcsdf.each_price.isnull().sum())\n",
    "\n",
    "upcsdf=upcsdf.dropna(subset=['upc', 'each_price'])\n",
    "print('after dropna: ',upcsdf.shape, upcsdf.each_price.isnull().sum())\n",
    "\n",
    "upcsdf=preprocess_upc(upcsdf)\n",
    "print('after preprocess_upc: ',upcsdf.shape, upcsdf.each_price.isnull().sum())\n",
    "\n",
    "upcsdf=preprocess_price(upcsdf)\n",
    "print('after preprocess_price: ',upcsdf.shape, upcsdf.each_price.isnull().sum())\n",
    "\n",
    "upcsdf=upcsdf.reset_index(drop=True)\n",
    "print('after reset_index: ',upcsdf.shape, upcsdf.each_price.isnull().sum())\n",
    "\n",
    "upcsdf.to_excel(f'{merged_dir}/upcsdf.xlsx', index=False)\n",
    "print('after save: ',upcsdf.shape, upcsdf.each_price.isnull().sum())\n",
    "\n",
    "print('done 14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. upload merged asin and upc on gdrive\n",
    "tree=['Supplier Catalogues', 'AUTOMATION', 'ScanUnlimited_ALL']\n",
    "folder_id=g.find_gdrive_folder_id(tree, folder_id='root')\n",
    "# delete existing ScanUnlimited_ALL\n",
    "g.delete_by_id(folder_id)\n",
    "# create new ScanUnlimited_ALL\n",
    "tree=['Supplier Catalogues', 'AUTOMATION']\n",
    "parent_folder_id=g.find_gdrive_folder_id(tree, folder_id='root')\n",
    "new_folder_id=g.create_folder(parent_folder_id, 'ScanUnlimited_ALL')\n",
    "g.upload_file(new_folder_id, f'{merged_dir}/asinsdf.xlsx')\n",
    "g.upload_file(new_folder_id, f'{merged_dir}/upcsdf.xlsx')\n",
    "print('done 16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "    Total:   {asinsdf.shape[0]+upcsdf.shape[0]}\n",
    "    upcsdf:  {upcsdf.shape[0]}\n",
    "    asinsdf: {asinsdf.shape[0]}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: shutil.rmtree(TMP_DIR)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add sheet name column so it shortens the download function\n",
    "# change ignore to active\n",
    "# add other columns list column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(addr, subject, body):\n",
    "    fromaddr = \"contact@tricyons.com\"\n",
    "    pswd     = \"tricyons123\"\n",
    "\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = formataddr(('Tricyons LLC', fromaddr))\n",
    "    msg['To'] = addr\n",
    "    msg['Subject'] = subject\n",
    "    body = body\n",
    "\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "    # smtpserver = smtplib.SMTP(\"mail.tricyons.com\", 465) # tls\n",
    "\n",
    "    server = smtplib.SMTP(\"mail.tricyons.com\", 26) # non-tls\n",
    "    server.starttls()\n",
    "    server.login(fromaddr, pswd)\n",
    "\n",
    "    text = msg.as_string()\n",
    "    server.sendmail(fromaddr, addr, text)\n",
    "    server.quit()    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailsdf=data[(data.Active==True) & (data.Type=='EMAIL')].sort_values('Email', ascending=False)\n",
    "print(emailsdf.shape)\n",
    "emailsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./email_catalog.txt', 'r') as f:\n",
    "    email_body_template = f.read()\n",
    "\n",
    "print(email_body_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_subject='Updated Catalog'\n",
    "\n",
    "for i, row in emailsdf.iterrows():\n",
    "    print(f'{i+1}/{emailsdf.shape[0]}', end='\\r')\n",
    "\n",
    "    email_to=row.Email.strip().lower()\n",
    "\n",
    "    email_body=email_body_template.replace('SUBJECT_NAME_TAG', row.Email_Subject)\n",
    "\n",
    "    email_sent = send_email(email_to, email_subject, email_body)\n",
    "    if not email_sent: print(f'Error in sending email to: {row.Email_Subject}')\n",
    "\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open('./email_template.txt', 'r') as f:\n",
    "    email_body_template = f.read()\n",
    "\n",
    "print(email_body_template)\n",
    "\n",
    "\n",
    "# email_to='faysalaslam887@gmail.com'\n",
    "# email_subject = \"Testing Email Body 3 Spaces\"\n",
    "# email_body=email_body_template.replace('COMPANY_NAME_TAG', 'Test Company')\n",
    "# send_email(email_to, email_subject, email_body)\n",
    "\n",
    "# g=GDrive()\n",
    "\n",
    "\n",
    "'''\n",
    "tmp_dir='./tmp/'\n",
    "\n",
    "tree=['Supplier Catalogues', 'Brands For Auto-Email']\n",
    "g.supplier_id=g.find_gdrive_folder_id(tree=tree, folder_id='root')\n",
    "g.download_files(g.supplier_id, tmp_dir)\n",
    "\n",
    "all_suppliers=pd.read_excel(f'{tmp_dir}/All Suppliers.xlsx')\n",
    "print(all_suppliers.shape)\n",
    "\n",
    "all_suppliers.head()\n",
    "\n",
    "df=all_suppliers.dropna(subset=['Email'], axis=0).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "# email_subject = \"Wholesale Account Opening\"\n",
    "\n",
    "# for i, row in df.iloc[78:].iterrows():\n",
    "#     print(f'{i+1}/{df.shape[0]}', end='\\r')\n",
    "\n",
    "#     email_to=row.Email.strip().lower()\n",
    "\n",
    "#     supplier_name = row.Name.strip()\n",
    "\n",
    "#     email_body=email_body_template.replace('COMPANY_NAME_TAG', supplier_name)\n",
    "\n",
    "#     email_sent = send_email(email_to, email_subject, email_body)\n",
    "#     if not email_sent: print(f'Error in sending email to: {supplier_name}')\n",
    "\n",
    "#     time.sleep(3)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test New Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "760e8a02d58bef947fb67df29745f4128d863e8829938df1158e073523dddf20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
